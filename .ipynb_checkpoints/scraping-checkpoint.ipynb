{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '../chromedriver91.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit Culver's website\n",
    "url = 'https://www.culvers.com/locator/view-all-locations'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse html\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<splinter.element_list.ElementList at 0x24db1fc7448>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and click state list\n",
    "states = browser.find_by_css('div')\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click Alabama\n",
    "states[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "inspirational\n",
      "life\n",
      "humor\n",
      "books\n",
      "reading\n",
      "friendship\n",
      "friends\n",
      "truth\n",
      "simile\n"
     ]
    }
   ],
   "source": [
    "# Scrape top ten tags\n",
    "tag_box = html_soup.find('div', class_='tags-box')\n",
    "\n",
    "tags = tag_box.find_all('a', class_='tag')\n",
    "\n",
    "for tag in tags:\n",
    "    word = tag.text\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://quotes.toscrape.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range (1, 6):\n",
    "    html = browser.html\n",
    "    quote_soup = soup(html, 'html.parser')\n",
    "    quotes = quote_soup.find_all('span', class_='text')\n",
    "    for quote in quotes:\n",
    "        print('page:', x, '----------')\n",
    "        print(quote.text)\n",
    "    browser.links.find_by_partial_text('Next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the ...\n",
      "Tipping the Velvet\n",
      "Soumission\n",
      "Sharp Objects\n",
      "Sapiens: A Brief History ...\n",
      "The Requiem Red\n",
      "The Dirty Little Secrets ...\n",
      "The Coming Woman: A ...\n",
      "The Boys in the ...\n",
      "The Black Maria\n",
      "Starving Hearts (Triangular Trade ...\n",
      "Shakespeare's Sonnets\n",
      "Set Me Free\n",
      "Scott Pilgrim's Precious Little ...\n",
      "Rip it Up and ...\n",
      "Our Band Could Be ...\n",
      "Olio\n",
      "Mesaerion: The Best Science ...\n",
      "Libertarianism for Beginners\n",
      "It's Only the Himalayas\n"
     ]
    }
   ],
   "source": [
    "# Skill Drill - Find Book URLs from http://books.toscrape.com/ - Currently finds the alias of link, not url itself, which is apparently what we wanted?s\n",
    "\n",
    "url = 'http://books.toscrape.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')\n",
    "\n",
    "urls = html_soup.find_all('h3')\n",
    "\n",
    "for url in urls:\n",
    "    title = url.text\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_title': 'Testing Proves Its Worth With Successful Mars Parachute Deployment', 'news_paragraph': 'The giant canopy that helped land Perseverance on Mars was tested here on Earth at NASA’s Wallops Flight Facility in Virginia.', 'featured_image': 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/image/featured/mars2.jpg', 'facts': '<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>value</th>\\n    </tr>\\n    <tr>\\n      <th>description</th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Equatorial Diameter:</th>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>Polar Diameter:</th>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.39 × 10^23 kg (0.11 Earths)</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Distance:</th>\\n      <td>227,943,824 km (1.38 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Period:</th>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>Surface Temperature:</th>\\n      <td>-87 to -5 °C</td>\\n    </tr>\\n    <tr>\\n      <th>First Record:</th>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>Recorded By:</th>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>', 'last modified': datetime.datetime(2021, 3, 2, 20, 12, 37, 939190)}\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import datetime as dt\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_all():\n",
    "    # Initiate headless driver for deployment\n",
    "    browser = Browser(\"chrome\", executable_path= \"../chromedriver\", headless=True)\n",
    "    news_title, news_paragraph = mars_news(browser)\n",
    "\n",
    "    # Run all scraping functions and store results in dictionary\n",
    "    data = {\n",
    "        \"news_title\": news_title,\n",
    "        \"news_paragraph\": news_paragraph,\n",
    "        \"featured_image\": featured_image(browser),\n",
    "        \"facts\": mars_facts(),\n",
    "        \"last modified\": dt.datetime.now()\n",
    "    }\n",
    "    # Stop webdriver, return data\n",
    "    browser.quit()\n",
    "    return data\n",
    "\n",
    "def mars_news(browser):\n",
    "    # Visit mars nasa news site\n",
    "    url = 'https://mars.nasa.gov/news/'\n",
    "    browser.visit(url)\n",
    "    \n",
    "    # Optional delay for loading page\n",
    "    browser.is_element_present_by_css(\"ul.item_list li.slide\", wait_time=1)\n",
    "\n",
    "    # Convert browser html to soup object\n",
    "    html = browser.html\n",
    "    news_soup = soup(html, 'html.parser')\n",
    "    try: \n",
    "        slide_elem = news_soup.select_one('ul.item_list li.slide')\n",
    "        # slide_elem.find(\"div\", class_='content_title')\n",
    "        # Use parent element to find first 'a' tag and save as 'news_title'\n",
    "        news_title = slide_elem.find(\"div\", class_='content_title').get_text()\n",
    "        # Use parent element paragraph text\n",
    "        news_p = slide_elem.find(\"div\", class_='article_teaser_body').get_text()\n",
    "    except AttributeError:\n",
    "        return None, None\n",
    "    return news_title, news_p\n",
    "\n",
    "def featured_image(browser):\n",
    "    # Visit URL\n",
    "    url = 'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/index.html'\n",
    "    browser.visit(url)\n",
    "\n",
    "    # Find and click full image button\n",
    "    full_image_elem = browser.find_by_tag('button')[1]\n",
    "    full_image_elem.click()\n",
    "\n",
    "    # Parse html with soup\n",
    "    html = browser.html\n",
    "    img_soup = soup(html, 'html.parser')\n",
    "\n",
    "    try: \n",
    "        # Find relative image url\n",
    "        img_url_rel = img_soup.find('img', class_='fancybox-image').get('src')\n",
    "\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "    # Use base url to create full url\n",
    "    img_url = f'https://data-class-jpl-space.s3.amazonaws.com/JPL_Space/{img_url_rel}'\n",
    "    return img_url\n",
    "\n",
    "def mars_facts():\n",
    "    try:  \n",
    "        # Scrape table into df\n",
    "        df = pd.read_html('http://space-facts.com/mars/')[0]\n",
    "    except BaseException:\n",
    "        return None\n",
    "\n",
    "    # Assign columns and set df index\n",
    "    df.columns=['description', 'value']\n",
    "    df.set_index('description', inplace=True)\n",
    "\n",
    "    # Convert df to html, add bootstrap\n",
    "    return df.to_html()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # If running as script, print scripted data\n",
    "    print(scrape_all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
